{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da9b707",
   "metadata": {},
   "source": [
    "# LSTM Challange Platinum Binar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2339a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "from sklearn.model_selection import train_test_split #split data train vs test\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer #token generator\n",
    "from tensorflow.keras.utils import pad_sequences,to_categorical #penyaman panjang array\n",
    "\n",
    "from imblearn.over_sampling import SMOTE #kalau kondisi datanya overfit\n",
    "\n",
    "from tensorflow.keras.models import Sequential #cara kerja ml secara berurut(serial)\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM #layer pada fungsi ML\n",
    "from tensorflow.keras.callbacks import EarlyStopping #untuk stop ML kalo udah gk nemu titik loss lebih rendah\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score #hasil kemampuan machine learning\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #transalate label menjadi indeks (untuk kasus lebih dari 2 variabel)\n",
    "from tensorflow.keras.utils import to_categorical #Membuat array 1 dimensi(dari hasil label encoder) jadi array 2 dimensi\n",
    "\n",
    "import tensorflow as tf #ini buat GPU TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f59a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "#Penggunaan GPU untuk TF\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58dc8cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                kalimat        HS\n",
      "0     tempat yang nyaman untuk berkumpul dengan tema...  positive\n",
      "1     memang banyak bacot sih , omongan doang gede b...  negative\n",
      "2     buat yang berkunjung ke bandung , yang ingin m...  positive\n",
      "3     restoran menyajikan makanan khas sunda yang en...  positive\n",
      "4     kalau travelling ke bandung , wajib makan bata...  positive\n",
      "...                                                 ...       ...\n",
      "9895  warung nasi ampera memiliki konsep rumah makan...  positive\n",
      "9896  mbak della sangat baik dan ramah , makanna nya...  positive\n",
      "9897  suasana nya sangat romantis jika makan malam d...  positive\n",
      "9898  masyarakat tidak kecewa jika dipimpin oleh jok...  positive\n",
      "9899  mau itu pak ridwan kamil atau pak dedi mulyadi...  positive\n",
      "\n",
      "[9900 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Data Frame\n",
    "df = pd.read_csv('train_data.csv')\n",
    "df.columns = ['kalimat','HS']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7335b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi cleansing data \n",
    "def preprocessing_text(text):\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"\\\\n\",\" \")\n",
    "    text = re.sub(r\"(\\s)(\\1+)\",r\"\\1\",text)\n",
    "    text = text.replace(\"rt\",\"\")\n",
    "    text = text.replace(\"user \",\"\")\n",
    "    text = text.replace(\" user\",\"\")\n",
    "    text = re.sub(r\"([a-z])(\\1{3,})\",r\"\\1\\1\",text)\n",
    "    text = re.sub(r\"(\\\\x)([a-z0-9]{2})\",r\"\",text)\n",
    "    text = text.replace(\"\\\\x8\",\"\")\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07aeca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleansing Data Tweet\n",
    "df['cleaned_kalimat'] = df.kalimat.apply(lambda x:preprocessing_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b263e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data Training vs Data Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['cleaned_kalimat'],df['HS'], random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a72c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizer buat mecah kalimat jadi kata - kata \n",
    "max_features = 10000\n",
    "tknzr = Tokenizer(num_words=max_features,\n",
    "                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                  split=' ', lower=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66811608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5281             banyak keluarga saya yang bekerja di bjb\n",
      "2929    cebong memang cetek otak nya kelamaan berendem...\n",
      "5167    anjirlah . saya tidak suka kamu karena menurut...\n",
      "5255    hop hop the bubble drinks di mal bandung indah...\n",
      "3078    saya muak dengan keputusan offside yang sebetu...\n",
      "                              ...                        \n",
      "9225    memang islam itu agama tidak bermoral cacat lonte\n",
      "4859    setelah pulang kerja , saya bersama seorang te...\n",
      "3264    sudirman said mengelaborasi sejumlah isu yang ...\n",
      "9845    bermula saat rapat di bandung , pukul 09.00 di...\n",
      "2732    fpi belum bubar ya . jika terus-terus buat rus...\n",
      "Name: cleaned_kalimat, Length: 7920, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3740e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenisasi kalimat \n",
    "tknzr.fit_on_texts(X_train) # Tokenisasi\n",
    "X_train = tknzr.texts_to_sequences(X_train)# Proses token di translate jadi indeks\n",
    "X_train = pad_sequences(X_train, maxlen=64)# Proses penyamanaan banyak indeks dalam suatu array\n",
    "y_train = pd.get_dummies(y_train).values\n",
    "\n",
    "X_val = tknzr.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(X_val, maxlen=64)\n",
    "y_val = pd.get_dummies(y_val).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01fbd14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tknzr.pickle has created!\n"
     ]
    }
   ],
   "source": [
    "# save tokenizer\n",
    "import pickle\n",
    "\n",
    "with open('tknzr.pickle', 'wb') as handle:\n",
    "    pickle.dump(tknzr, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"tknzr.pickle has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83777737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Fixing Overfitting data\n",
    "smote = SMOTE() #dipake untuk kalo label data jomplang biar disamain \n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9b76653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Model Machine Learning LSTM\n",
    "max_nb_words = tknzr.num_words\n",
    "embed_dim = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_nb_words,embed_dim,input_length=64))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94c025e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 64, 64)            640000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 675,203\n",
      "Trainable params: 675,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Compile Model Machine Learning LSTM\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21f60ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config toggle untuk menjalankan library to_categorical\n",
    "tf.config.run_functions_eagerly(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a5862d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Syauqi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 118s 544ms/step - loss: 0.7759 - accuracy: 0.6433 - val_loss: 0.5402 - val_accuracy: 0.7859\n",
      "Epoch 2/10\n",
      "216/216 [==============================] - 106s 492ms/step - loss: 0.4853 - accuracy: 0.8040 - val_loss: 0.4678 - val_accuracy: 0.8197\n",
      "Epoch 3/10\n",
      "216/216 [==============================] - 114s 529ms/step - loss: 0.3310 - accuracy: 0.8733 - val_loss: 0.4616 - val_accuracy: 0.8237\n",
      "Epoch 4/10\n",
      "216/216 [==============================] - 111s 513ms/step - loss: 0.2307 - accuracy: 0.9142 - val_loss: 0.5503 - val_accuracy: 0.8131\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Validasi Model\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee9d8b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 143ms/step\n"
     ]
    }
   ],
   "source": [
    "#Mengetest model yang sudah belajar dengan Test Data\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31cb1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cara Menilai Positive/Negative/Neutral(menggunakan pembulatan hasil)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "#Transform array HS menjadi indeks(0/1/2)\n",
    "y_true = np.argmax(y_val,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c786221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 ... 2 2 0]\n",
      "[2 0 2 ... 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e720d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8131313131313131\n",
      "(0.7581753656916236, 0.7907112168292848, 0.770769066827682, None)\n"
     ]
    }
   ],
   "source": [
    "#Hasil Model\n",
    "print(accuracy_score(y_pred=y_pred, y_true=y_true))\n",
    "print(precision_recall_fscore_support(y_pred=y_pred, y_true=y_true, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38f13286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tes teks\n",
    "def test(kalimat):\n",
    "    input_kalimat = [kalimat]\n",
    "    input_kalimat = tknzr.texts_to_sequences(input_kalimat)\n",
    "    input_kalimat = pad_sequences(input_kalimat, maxlen=64)\n",
    "    \n",
    "    hasil = model.predict(input_kalimat)\n",
    "    hasil = hasil.argmax(axis=1)\n",
    "\n",
    "    \n",
    "    # konversi nilai prediksi menjadi label sentimen\n",
    "    labels = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    hasil = labels[hasil[0]]\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "898a6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampel kalimat yang mau ditest\n",
    "Sampel = \"makan ini enak sekali\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfaf4fd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Syauqi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(Sampel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7102901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has created!\n"
     ]
    }
   ],
   "source": [
    "#Simpan model\n",
    "model.save('model_lstm.h5')\n",
    "print(\"Model has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d9e8a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berhasil\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "from keras.models import load_model\n",
    "model_LSTM = load_model(\"model_lstm.h5\")\n",
    "print(\"berhasil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70842645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file = open(\"tknzr.pickle\",\"rb\")\n",
    "tknzr = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "print(\"Berhasil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb847e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tes file\n",
    "def test_file_nn(kalimat):\n",
    "    input_kalimat = df['text_clean']\n",
    "    input_kalimat = tknzr.texts_to_sequences(input_kalimat)\n",
    "    input_kalimat = pad_sequences(input_kalimat, maxlen=max_features)\n",
    "    \n",
    "    hasil = model_LSTM.predict(input_kalimat)\n",
    "    hasil = hasil.argmax(axis=1)\n",
    "\n",
    "    \n",
    "    # konversi nilai prediksi menjadi label sentimen\n",
    "    labels = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    df[\"label_prediksi\"] = [labels[hasil] for pred in hasil]\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
